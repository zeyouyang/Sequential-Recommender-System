{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a287c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import (SnowballStemmer)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c614e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = torch.load('C://Users//user//Desktop//王茂田//item.pt')\n",
    "duration=torch.load('C://Users//user//Desktop//王茂田//duration.pt')\n",
    "interval=torch.load('C://Users//user//Desktop//王茂田//interval.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32aed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = item.numpy().tolist()\n",
    "duration = duration.numpy().tolist()\n",
    "interval = interval.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f20abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_item=[]\n",
    "target_duration=[]\n",
    "target_interval=[]\n",
    "\n",
    "for i in range (len(item)):\n",
    "    target_item=target_item+(item[i][-1:])\n",
    "    \n",
    "for i in range (len(duration)):\n",
    "    target_duration=target_duration+(duration[i][-1:])\n",
    "    \n",
    "for i in range (len(interval)):\n",
    "    target_interval=target_interval+(interval[i][-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_item=[]\n",
    "input_duration=[]\n",
    "input_interval=[]\n",
    "\n",
    "for i in range (len(item)):\n",
    "    input_item.append(item[i][:-1])\n",
    "    \n",
    "for i in range (len(duration)):\n",
    "    input_duration.append(duration[i][:-1])\n",
    "    \n",
    "for i in range (len(interval)):\n",
    "    input_interval.append(interval[i][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_of_lists1=(input_item,target_item,input_duration,target_duration,input_interval,target_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300937d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "l1=random.sample(range(0,len(lists_of_lists1[0])),int(len(lists_of_lists1[0])*0.7))\n",
    "train_data=[[],[],[],[],[],[],[]]\n",
    "test_data=[[],[],[],[],[],[],[]]\n",
    "for i in range(len(lists_of_lists1[0])):\n",
    "    if i in set(l1):\n",
    "        train_data[0].append(lists_of_lists1[0][i])\n",
    "        train_data[1].append(lists_of_lists1[1][i])\n",
    "        train_data[2].append(lists_of_lists1[2][i])\n",
    "        train_data[3].append(lists_of_lists1[3][i])\n",
    "        train_data[4].append(lists_of_lists1[4][i])\n",
    "        train_data[5].append(lists_of_lists1[5][i])\n",
    "        train_data[6].append(len(lists_of_lists1[0][i]))\n",
    "    else:\n",
    "        test_data[0].append(lists_of_lists1[0][i])\n",
    "        test_data[1].append(lists_of_lists1[1][i])\n",
    "        test_data[2].append(lists_of_lists1[2][i])\n",
    "        test_data[3].append(lists_of_lists1[3][i])\n",
    "        test_data[4].append(lists_of_lists1[4][i])\n",
    "        test_data[5].append(lists_of_lists1[5][i])\n",
    "        test_data[6].append(len(lists_of_lists1[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0] = torch.LongTensor(train_data[0]).to(torch.int64)\n",
    "train_data[1] = torch.LongTensor(train_data[1]).to(torch.int64)\n",
    "train_data[2] = torch.LongTensor(train_data[2]).to(torch.int64)\n",
    "train_data[3] = torch.LongTensor(train_data[3]).to(torch.int64)\n",
    "train_data[4] = torch.LongTensor(train_data[4]).to(torch.int64)\n",
    "train_data[5] = torch.LongTensor(train_data[5]).to(torch.int64)\n",
    "train_data[6] = torch.LongTensor(train_data[6]).to(torch.int64)\n",
    "\n",
    "test_data[0] = torch.LongTensor(test_data[0]).to(torch.int64)\n",
    "test_data[1] = torch.LongTensor(test_data[1]).to(torch.int64)\n",
    "test_data[2] = torch.LongTensor(test_data[2]).to(torch.int64)\n",
    "test_data[3] = torch.LongTensor(test_data[3]).to(torch.int64)\n",
    "test_data[4] = torch.LongTensor(test_data[4]).to(torch.int64)\n",
    "test_data[5] = torch.LongTensor(test_data[5]).to(torch.int64)\n",
    "test_data[6] = torch.LongTensor(test_data[6]).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4382acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "train = data_utils.TensorDataset(train_data[0], train_data[1],train_data[2],train_data[3], train_data[4],train_data[5],train_data[6])\n",
    "test = data_utils.TensorDataset(test_data[0],test_data[1], test_data[2],test_data[3],test_data[4], test_data[5], test_data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#載入dataloader，並選擇batch_size\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "a = dataiter.next()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74dbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NARM(nn.Module):\n",
    "    # NARM主架構 不用動\n",
    "    def __init__(self, emb_size, hidden_size, attention_size):\n",
    "        super(NARM, self).__init__()\n",
    "       \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_size = attention_size\n",
    "        \n",
    "        \n",
    "        self.it_embedding = nn.Embedding(776, self.emb_size)\n",
    "        self.du_embedding = nn.Embedding(21, self.emb_size)\n",
    "        self.int_embedding = nn.Embedding(21, self.emb_size)\n",
    "        \n",
    "        self.encoder_g = nn.GRU(input_size=self.emb_size*3, hidden_size=self.hidden_size*3, batch_first=True)\n",
    "        self.encoder_l = nn.GRU(input_size=self.emb_size*3, hidden_size=self.hidden_size*3, batch_first=True)\n",
    "        self.A1 = nn.Linear(self.hidden_size*3, self.attention_size*3, bias=False)\n",
    "        self.A2 = nn.Linear(self.hidden_size*3, self.attention_size*3, bias=False)\n",
    "        self.attention_out = nn.Linear(self.attention_size*3, 1, bias=False)\n",
    "        self.out_it = nn.Linear(2*self.hidden_size*3, 776, bias=False)\n",
    "        self.out_du = nn.Linear(2*self.hidden_size*3, 21, bias=False)\n",
    "        self.out_int = nn.Linear(2*self.hidden_size*3, 21, bias=False)\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "\n",
    "        items= input['item']\n",
    "        target_items = input['target_item']\n",
    "        durations = input['duration'] \n",
    "        target_durations = input['target_duration']\n",
    "        intervals = input['interval'] \n",
    "        target_intervals = input['target_interval'] \n",
    "        lengths = input['lengths']\n",
    "        # Embedding Layer\n",
    "        embedded_item = self.it_embedding(items)\n",
    "   \n",
    "        embedded_duration = self.du_embedding(durations)\n",
    "        embedded_interval = self.int_embedding(intervals)\n",
    "        \n",
    "        i_vectors =  torch.cat((embedded_item,embedded_duration,embedded_interval),dim=2)\n",
    "\n",
    "        # Encoding Layer\n",
    "        sort_his_lengths, sort_idx = torch.topk(lengths, k=len(lengths))\n",
    "\n",
    "        sort_his_vectors = i_vectors.index_select(dim=0, index=sort_idx)\n",
    "        history_packed = nn.utils.rnn.pack_padded_sequence(sort_his_vectors, sort_his_lengths.cpu(), batch_first=True)\n",
    "        _, hidden_g = self.encoder_g(history_packed, None)\n",
    "        output_l, hidden_l = self.encoder_l(history_packed, None)\n",
    "        output_l, _ = torch.nn.utils.rnn.pad_packed_sequence(output_l, batch_first=True)\n",
    "        unsort_idx = torch.topk(sort_idx, k=len(lengths), largest=False)[1]\n",
    "        output_l = output_l.index_select(dim=0, index=unsort_idx)  # [batch_size, history_max, emb_size]\n",
    "        hidden_g = hidden_g[-1].index_select(dim=0, index=unsort_idx)  # [batch_size, emb_size]\n",
    "\n",
    "        # Attention Layer\n",
    "        attention_g = self.A1(hidden_g)\n",
    "        attention_l = self.A2(output_l)\n",
    "        attention_value = self.attention_out((attention_g[:, None, :] + attention_l).sigmoid())\n",
    "        mask = (items > 0).unsqueeze(-1)\n",
    "       \n",
    "        attention_value = attention_value.masked_fill(mask == 0, 0)\n",
    "        c_l = (attention_value * output_l).sum(1)\n",
    "\n",
    "      \n",
    "        \n",
    "        output1 = self.out_it(torch.cat((hidden_g, c_l), dim=1))\n",
    "        output2 = self.out_du(torch.cat((hidden_g, c_l), dim=1))\n",
    "        output3 = self.out_int(torch.cat((hidden_g, c_l), dim=1))\n",
    "        \n",
    "        return output1,output2,output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09641bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size, hidden_size, attention_size = 128, 128, 128\n",
    "model = NARM(emb_size, hidden_size, attention_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fcdcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4534a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fa1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定訓練步驟\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.99), eps=1e-8)\n",
    "epochs = 30\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "logs = []\n",
    "prod_all = []\n",
    "label_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "for epoch in range(epochs):\n",
    "    co = 0\n",
    "\n",
    "    correct_duration=0\n",
    "    correct_interval=0\n",
    "  \n",
    "    train_loss_sum = 0.0\n",
    "    \n",
    "    train_loss = list()\n",
    "\n",
    "    start_time = timer()\n",
    "    model.train()\n",
    "   \n",
    "    b = []\n",
    "    m, t= 0,0\n",
    "    re3_it, re5_it, re10_it,  ra_it = 0, 0, 0, 0\n",
    "    re2_du, re3_du, re5_du,  ra_du = 0, 0, 0, 0\n",
    "    re2_int, re3_int, re5_int,  ra_int = 0, 0, 0, 0\n",
    "    m3_it,m5_it,m10_it=0,0,0\n",
    "    nd3_it,nd5_it,nd10_it=0,0,0\n",
    "    \n",
    "    m2_du,m3_du,m5_du=0,0,0\n",
    "    nd2_du,nd3_du,nd5_du=0,0,0\n",
    "    \n",
    "    m2_int,m3_int,m5_int=0,0,0\n",
    "    nd2_int,nd3_int,nd5_int=0,0,0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for batch, data in enumerate(train_loader):\n",
    "        #將input的tuple分成三個部分\n",
    "        \n",
    "        input = { 'item': data[0].to(device),\n",
    "                  'target_item': data[1].to(device),\n",
    "                  'duration': data[2].to(device),\n",
    "                  'target_duration': data[3].to(device),\n",
    "                  'interval': data[4].to(device),\n",
    "                  'target_interval': data[5].to(device),\n",
    "                  'lengths': data[6].to(device),\n",
    "                 }\n",
    "        logits_it,logits_du,logits_int = model(input)\n",
    "        l_it = logits_it\n",
    "        l_du = logits_du\n",
    "        l_int = logits_int\n",
    "        tgt_it = input['target_item']\n",
    "        tgt_du = input['target_duration']\n",
    "        tgt_int = input['target_interval']\n",
    "        \n",
    "       \n",
    "        # CROSS比較train跟target\n",
    "        loss_it = loss_fn(l_it, tgt_it)\n",
    "        loss_du = loss_fn(l_du, tgt_du)\n",
    "        loss_int = loss_fn(l_int, tgt_int)\n",
    "        \n",
    "        loss = 0.4*loss_it + 0.3*loss_du +0.3*loss_int\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_sum += loss.item()\n",
    "       \n",
    "        \n",
    "        \n",
    " \n",
    "    train_loss = train_loss_sum / len(train_loader)\n",
    "    train_time = round(timer() - start_time)\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    import heapq\n",
    "    \n",
    "   \n",
    "\n",
    "    for batch, data in tqdm(enumerate(test_loader)):   \n",
    "        input = { 'item': data[0].to(device),\n",
    "                  'target_item': data[1].to(device),\n",
    "                  'duration': data[2].to(device),\n",
    "                  'target_duration': data[3].to(device),\n",
    "                  'interval': data[4].to(device),\n",
    "                  'target_interval': data[5].to(device),\n",
    "                  'lengths': data[6].to(device),\n",
    "                 }\n",
    "\n",
    "        logits_it,logits_du,logits_int = model(input)\n",
    "   \n",
    "        l_it = logits_it\n",
    "        l_du = logits_du\n",
    "        l_int = logits_int\n",
    "        tgt_it = input['target_item']\n",
    "        tgt_du = input['target_duration']\n",
    "        tgt_int = input['target_interval']\n",
    "        \n",
    "\n",
    "        \n",
    "        l_it =  l_it.cpu().data.numpy()\n",
    "        l_du =  l_du.cpu().data.numpy()\n",
    "        l_int =  l_int.cpu().data.numpy()\n",
    "        ranks_it = 0\n",
    "        ranks3_it = 0\n",
    "        ranks5_it = 0\n",
    "        ranks10_it = 0\n",
    "        ndcg3_it=0\n",
    "        ndcg5_it=0\n",
    "        ndcg10_it=0\n",
    "        \n",
    "        ranks_du = 0\n",
    "        ranks2_du = 0\n",
    "        ranks3_du = 0\n",
    "        ranks5_du = 0\n",
    "        ndcg2_du=0\n",
    "        ndcg3_du=0\n",
    "        ndcg5_du=0\n",
    "        \n",
    "        ranks_int = 0\n",
    "        ranks2_int = 0\n",
    "        ranks3_int = 0\n",
    "        ranks5_int = 0\n",
    "        ndcg2_int=0\n",
    "        ndcg3_int=0\n",
    "        ndcg5_int=0\n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "       #####item\n",
    "        # 將前k個結果取出做比較\n",
    "        for n in range(len(l_it)):\n",
    "             \n",
    "            r3= heapq.nlargest(3, range(len(l_it[n])), l_it[n].take) \n",
    "\n",
    "            \n",
    "            for i in range(len(r3)):\n",
    "                re3_it += ((r3[i]) == tgt_it[n]).float().sum()\n",
    "                \n",
    "            r5= heapq.nlargest(5, range(len(l_it[n])), l_it[n].take)\n",
    "       \n",
    "            for i in range(len(r5)):\n",
    "                re5_it += ((r5[i]) == tgt_it[n]).float().sum()\n",
    "                \n",
    "                \n",
    "            r10= heapq.nlargest(10, range(len(l_it[n])), l_it[n].take)\n",
    "          \n",
    "            for i in range(len(r10)):\n",
    "                re10_it += ((r10[i]) ==tgt_it[n]).float().sum()\n",
    "            \n",
    "          #MRR3\n",
    "            mr3 = r3\n",
    "            for i in range(len(mr3)):\n",
    "                if (mr3[i]) == tgt_it[n]:\n",
    "                    rank3 = i + 1\n",
    "                    rranks3 = 1/rank3\n",
    "\n",
    "                    m3_it += rranks3\n",
    "                    nndcg3=(1/(np.log2(rank3+1)))\n",
    "                    nd3_it+=nndcg3\n",
    "        #MRR\n",
    "            mr5 = r5\n",
    "\n",
    "            for i in range(len(mr5)):\n",
    "               \n",
    "                if (mr5[i]) == tgt_it[n]:\n",
    "                    rank5 = i + 1\n",
    "                    rranks5 = 1/rank5\n",
    "                    m5_it += rranks5\n",
    "                    nndcg5=(1/(np.log2(rank5+1)))\n",
    "                    nd5_it+=nndcg5\n",
    "    \n",
    "    \n",
    "    #MRR\n",
    "            mr10 = r10\n",
    "\n",
    "            for i in range(len(mr10)):\n",
    "                if (mr10[i]) == tgt_it[n]:\n",
    "                    rank10 = i + 1\n",
    "                   \n",
    "                    rranks10 = 1/rank10\n",
    "                    m10_it += rranks10\n",
    "                    nndcg10=1/(np.log2(rank10+1))\n",
    "                    nd10_it+=nndcg10\n",
    "        \n",
    "         #####duration\n",
    "        # 將前k個結果取出做比較      \n",
    "        \n",
    "        \n",
    "        for n in range(len(l_du)):\n",
    "            \n",
    "            r1= heapq.nlargest(1,  range(len(l_du[n])), l_du[n].take) \n",
    "            \n",
    "            \n",
    "            for i in range(len(r1)):\n",
    "                correct_duration += (((r1[i]) == tgt_du[n]).float().sum())\n",
    "            \n",
    "            \n",
    "            r2= heapq.nlargest(2,  range(len(l_du[n])), l_du[n].take) \n",
    "                \n",
    "      \n",
    "            for i in range(len(r2)):\n",
    "                re2_du += (((r2[i]) == tgt_du[n]).float().sum())\n",
    "            \n",
    "            \n",
    "            r3= heapq.nlargest(3,  range(len(l_du[n])), l_du[n].take) \n",
    "         \n",
    "            for i in range(len(r3)):\n",
    "                re3_du += (((r3[i]) == tgt_du[n]).float().sum())\n",
    "            \n",
    "            r5= heapq.nlargest(5,  range(len(l_du[n])), l_du[n].take) \n",
    "            \n",
    "            for i in range(len(r5)):\n",
    "                re5_du += (((r5[i]) ==tgt_du[n]).float().sum())\n",
    "                \n",
    "           \n",
    "                           \n",
    "          #MRR3\n",
    "            mr2 = r2\n",
    "            for i in range(len(mr2)):\n",
    "                if ((mr2[i]) == tgt_du[n]):\n",
    "                    rank2 = i + 1\n",
    "                    rranks2 = 1/rank2\n",
    "\n",
    "                    m2_du += rranks2\n",
    "                    nndcg2=(1/(np.log2(rank2+1)))\n",
    "                    nd2_du+=nndcg2\n",
    "        #MRR\n",
    "            mr3 = r3\n",
    "\n",
    "            for i in range(len(mr3)):\n",
    "               \n",
    "                if ((mr3[i]) == tgt_du[n]):\n",
    "                    rank3 = i + 1\n",
    "                    rranks3 = 1/rank3\n",
    "                    \n",
    "                    m3_du += rranks3\n",
    "                    nndcg3=(1/(np.log2(rank3+1)))\n",
    "                    nd3_du+=nndcg3\n",
    "    \n",
    "\n",
    "    #MRR\n",
    "            mr5 = r5\n",
    "\n",
    "            for i in range(len(mr5)):\n",
    "                if ((mr5[i]) == tgt_du[n]):\n",
    "                    rank5 = i + 1\n",
    "                   \n",
    "                    rranks5 = 1/rank5\n",
    "                    m5_du += rranks5\n",
    "                    nndcg5=1/(np.log2(rank5+1))\n",
    "                    nd5_du+=nndcg5\n",
    "       \n",
    "                    \n",
    "                      \n",
    "       \n",
    "           #####interval\n",
    "        # 將前k個結果取出做比較  \n",
    "        for n in range(len(l_int)):\n",
    "            \n",
    "            \n",
    "            r1= heapq.nlargest(1,  range(len(l_int[n])), l_int[n].take) \n",
    "           \n",
    "            for i in range(len(r1)):\n",
    "                correct_interval += (((r1[i]) == tgt_int[n]).float().sum())\n",
    "            \n",
    "            \n",
    "            r2= heapq.nlargest(2,  range(len(l_int[n])), l_int[n].take) \n",
    "            \n",
    "            \n",
    "            for i in range(len(r2)):\n",
    "                re2_int += (((r2[i])) == tgt_int[n]).float().sum()\n",
    "                \n",
    "            r3= heapq.nlargest(3,  range(len(l_int[n])), l_int[n].take) \n",
    "            \n",
    "            for i in range(len(r3)):\n",
    "                re3_int += (((r3[i])) == tgt_int[n]).float().sum()\n",
    "                \n",
    "            r5= heapq.nlargest(5,  range(len(l_int[n])), l_int[n].take) \n",
    "            \n",
    "     \n",
    "            for i in range(len(r5)):\n",
    "                re5_int += (((r5[i])) == tgt_int[n]).float().sum()\n",
    "            \n",
    "          #MRR3\n",
    "            mr2 = r2\n",
    "            for i in range(len(mr2)):\n",
    "                if (((mr2[i])) == tgt_int[n]):\n",
    "                    rank2 = i + 1\n",
    "                    rranks2 = 1/rank2\n",
    "\n",
    "                    m2_int += rranks2\n",
    "                    nndcg2=(1/(np.log2(rank2+1)))\n",
    "                    nd2_int+=nndcg2\n",
    "        #MRR\n",
    "            mr3 = r3\n",
    "\n",
    "            for i in range(len(mr3)):\n",
    "               \n",
    "                if ((mr3[i])) == tgt_int[n]:\n",
    "                    rank3 = i + 1\n",
    "                    rranks3 = 1/rank3\n",
    "                    m3_int += rranks3\n",
    "                    nndcg3=(1/(np.log2(rank3+1)))\n",
    "                    nd3_int+=nndcg3\n",
    "    \n",
    " \n",
    "    #MRR\n",
    "            mr5 = r5\n",
    "\n",
    "            for i in range(len(mr5)):\n",
    "                if ((mr5[i])) == tgt_int[n]:\n",
    "                    rank5 = i + 1\n",
    "                   \n",
    "                    rranks5 = 1/rank5\n",
    "                    m5_int += rranks5\n",
    "                    nndcg5 = 1/(np.log2(rank5+1))\n",
    "                    nd5_int+=nndcg5  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "   \n",
    "    \n",
    "    recall3_it = (re3_it*100)/(len(test_data[0]))\n",
    "    \n",
    "    recall5_it = (re5_it*100)/(len(test_data[0]))\n",
    "    recall10_it = (re10_it*100)/(len(test_data[0]))\n",
    "    mrr3_it = (m3_it*100)/(len(test_data[0]))\n",
    "    mrr5_it = (m5_it*100)/(len(test_data[0]))\n",
    "    mrr10_it = (m10_it*100)/(len(test_data[0]))\n",
    "    n3_it=(nd3_it*100)/(len(test_data[0]))\n",
    "    n5_it=(nd5_it*100)/(len(test_data[0]))\n",
    "    n10_it=(nd10_it*100)/(len(test_data[0]))\n",
    "   \n",
    "        \n",
    "        \n",
    "    recall2_du = (re2_du*100)/(len(test_data[0]))\n",
    "    recall3_du = (re3_du*100)/(len(test_data[0]))\n",
    "    recall5_du = (re5_du*100)/(len(test_data[0]))\n",
    "    mrr2_du = (m2_du*100)/(len(test_data[0]))\n",
    "    mrr3_du = (m3_du*100)/(len(test_data[0]))\n",
    "    mrr5_du = (m5_du*100)/(len(test_data[0]))\n",
    "    n2_du=(nd2_du*100)/(len(test_data[0]))\n",
    "    n3_du=(nd3_du*100)/(len(test_data[0]))\n",
    "    n5_du=(nd5_du*100)/(len(test_data[0]))\n",
    "    \n",
    "        \n",
    "        \n",
    "    recall2_int = (re2_int*100)/(len(test_data[0]))\n",
    "    recall3_int = (re3_int*100)/(len(test_data[0]))\n",
    "    recall5_int = (re5_int*100)/(len(test_data[0]))\n",
    "    mrr2_int = (m2_int*100)/(len(test_data[0]))\n",
    "    mrr3_int = (m3_int*100)/(len(test_data[0]))\n",
    "    mrr5_int = (m5_int*100)/(len(test_data[0]))\n",
    "    n2_int=(nd2_int*100)/(len(test_data[0]))\n",
    "    n3_int=(nd3_int*100)/(len(test_data[0]))\n",
    "    n5_int=(nd5_int*100)/(len(test_data[0]))\n",
    "\n",
    "        \n",
    "    accuracy_du = 100 * correct_duration/(len(test_data[0]))\n",
    "    accuracy_int = 100 * correct_interval/(len(test_data[0]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    log = f\"Accuracy_Duration: {accuracy_du:.5f} Accuracy_Interval: {accuracy_int:.5f} HR3_Item: {recall3_it:.5f} HR5_Item: {recall5_it:.5f} HR10_Item: {recall10_it:.5f} HR2_du: {recall2_du:.5f} HR3_du: {recall3_du:.5f}HR5_du: {recall5_du:.5f} HR2_int: {recall2_int:.5f} HR3_int: {recall3_int:.5f} HR5_int: {recall5_int:.5f}  MRR3_item: {mrr3_it:.10f}  MRR5_item: {mrr5_it:.10f}  MRR10_item: {mrr10_it:.10f} MRR2_du: {mrr2_du:.10f}  MRR3_du: {mrr3_du:.10f}  MRR5_du: {mrr5_du:.10f} MRR2_int: {mrr2_int:.10f}  MRR3_int: {mrr3_int:.10f}  MRR5_int: {mrr5_int:.10f}  NDCG3_it: {n3_it:.10f}  NDCG5_it: {n5_it:.10f}  NDCG10_it: {n10_it:.10f}  NDCG2_du: {n2_du:.10f}  NDCG3_du: {n3_du:.10f}  NDCG5_du: {n5_du:.10f}  NDCG2_int: {n2_int:.10f}  NDCG3_int: {n3_int:.10f}  NDCG5_int: {n5_int:.10f} \"\n",
    "        \n",
    "    print(log)\n",
    "    \n",
    "   # print(m/t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
