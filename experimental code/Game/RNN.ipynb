{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a287c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import (SnowballStemmer)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca49b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = torch.load('C://Users//user//Desktop//王茂田//item.pt')\n",
    "duration=torch.load('C://Users//user//Desktop//王茂田//duration.pt')\n",
    "interval=torch.load('C://Users//user//Desktop//王茂田//interval.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = item.numpy().tolist()\n",
    "duration = duration.numpy().tolist()\n",
    "interval = interval.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_item=[]\n",
    "target_duration=[]\n",
    "target_interval=[]\n",
    "\n",
    "for i in range (len(item)):\n",
    "    target_item=target_item+(item[i][-1:])\n",
    "    \n",
    "for i in range (len(duration)):\n",
    "    target_duration=target_duration+(duration[i][-1:])\n",
    "    \n",
    "for i in range (len(interval)):\n",
    "    target_interval=target_interval+(interval[i][-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04545a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_item=[]\n",
    "input_duration=[]\n",
    "input_interval=[]\n",
    "\n",
    "for i in range (len(item)):\n",
    "    input_item.append(item[i][:-1])\n",
    "    \n",
    "for i in range (len(duration)):\n",
    "    input_duration.append(duration[i][:-1])\n",
    "    \n",
    "for i in range (len(interval)):\n",
    "    input_interval.append(interval[i][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023913bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_of_lists1=(input_item,target_item,input_duration,target_duration,input_interval,target_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b099e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e59aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "l1=random.sample(range(0,len(lists_of_lists1[0])),int(len(lists_of_lists1[0])*0.7))\n",
    "train_data=[[],[],[],[],[],[]]\n",
    "test_data=[[],[],[],[],[],[]]\n",
    "for i in range(len(lists_of_lists1[0])):\n",
    "    if i in set(l1):\n",
    "        train_data[0].append(lists_of_lists1[0][i])\n",
    "        train_data[1].append(lists_of_lists1[1][i])\n",
    "        train_data[2].append(lists_of_lists1[2][i])\n",
    "        train_data[3].append(lists_of_lists1[3][i])\n",
    "        train_data[4].append(lists_of_lists1[4][i])\n",
    "        train_data[5].append(lists_of_lists1[5][i])\n",
    "    else:\n",
    "        test_data[0].append(lists_of_lists1[0][i])\n",
    "        test_data[1].append(lists_of_lists1[1][i])\n",
    "        test_data[2].append(lists_of_lists1[2][i])\n",
    "        test_data[3].append(lists_of_lists1[3][i])\n",
    "        test_data[4].append(lists_of_lists1[4][i])\n",
    "        test_data[5].append(lists_of_lists1[5][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0323d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0] = torch.LongTensor(train_data[0]).to(torch.int64)\n",
    "train_data[1] = torch.LongTensor(train_data[1]).to(torch.int64)\n",
    "train_data[2] = torch.LongTensor(train_data[2]).to(torch.int64)\n",
    "train_data[3] = torch.LongTensor(train_data[3]).to(torch.int64)\n",
    "train_data[4] = torch.LongTensor(train_data[4]).to(torch.int64)\n",
    "train_data[5] = torch.LongTensor(train_data[5]).to(torch.int64)\n",
    "\n",
    "\n",
    "test_data[0] = torch.LongTensor(test_data[0]).to(torch.int64)\n",
    "test_data[1] = torch.LongTensor(test_data[1]).to(torch.int64)\n",
    "test_data[2] = torch.LongTensor(test_data[2]).to(torch.int64)\n",
    "test_data[3] = torch.LongTensor(test_data[3]).to(torch.int64)\n",
    "test_data[4] = torch.LongTensor(test_data[4]).to(torch.int64)\n",
    "test_data[5] = torch.LongTensor(test_data[5]).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61687e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "train = data_utils.TensorDataset(train_data[0], train_data[1],train_data[2],train_data[3], train_data[4],train_data[5])\n",
    "test = data_utils.TensorDataset(test_data[0],test_data[1], test_data[2],test_data[3],test_data[4], test_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79981b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#載入dataloader，並選擇batch_size\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "a = dataiter.next()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f54e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedded_size,hidden_num):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # item_num, embedding_size\n",
    "        self.embedded_size = embedded_size\n",
    "        self.hidden_size = hidden_num\n",
    "        \n",
    "        self.it_embedding = nn.Embedding(776, self.embedded_size)\n",
    "        self.du_embedding = nn.Embedding(21, self.embedded_size)\n",
    "        self.int_embedding = nn.Embedding(21, self.embedded_size)\n",
    "       \n",
    "        \n",
    "        #主模型 (embedding_size, hidden_size)\n",
    "        self.RNN_layer = nn.RNN(self.embedded_size*3,self.hidden_size*3, batch_first=True)\n",
    "        #最終輸出層(Crossentropy)\n",
    "        self.out_it = nn.Linear(self.hidden_size*3, 776)\n",
    "        self.out_du = nn.Linear(self.hidden_size*3, 21)\n",
    "        self.out_int = nn.Linear(self.hidden_size*3, 21)\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        items = input['item'] \n",
    "        target_items = input['target_item']\n",
    "        durations = input['duration'] \n",
    "        target_durations = input['target_duration']\n",
    "        intervals = input['interval'] \n",
    "        target_intervals = input['target_interval'] \n",
    "        \n",
    "        embedded_item = self.it_embedding(items)\n",
    "   \n",
    "        embedded_duration = self.du_embedding(durations)\n",
    "        embedded_interval = self.int_embedding(intervals)\n",
    "        x = torch.cat((embedded_item,embedded_duration,embedded_interval),dim=2)\n",
    "        \n",
    "\n",
    "      \n",
    "        output, _ = self.RNN_layer(x)\n",
    "        output = output[:, -1, :]\n",
    "        output1 = self.out_it(output)\n",
    "        output2 = self.out_du(output)\n",
    "        output3 = self.out_int(output)\n",
    "        \n",
    "        return output1,output2,output3\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_num, hidden_num, output_num\n",
    "model = RNNModel(128,128)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf54e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定訓練步驟\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.99), eps=1e-8)\n",
    "epochs = 30\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "logs = []\n",
    "prod_all = []\n",
    "label_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8b617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742d0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "for epoch in range(epochs):\n",
    "    co = 0\n",
    "\n",
    "    correct_duration=0\n",
    "    correct_interval=0\n",
    "  \n",
    "    train_loss_sum = 0.0\n",
    "    \n",
    "    train_loss = list()\n",
    "\n",
    "    start_time = timer()\n",
    "    model.train()\n",
    "   \n",
    "    b = []\n",
    "    m, t= 0,0\n",
    "    re3_it, re5_it, re10_it,  ra_it = 0, 0, 0, 0\n",
    "    re2_du, re3_du, re5_du,  ra_du = 0, 0, 0, 0\n",
    "    re2_int, re3_int, re5_int,  ra_int = 0, 0, 0, 0\n",
    "    m3_it,m5_it,m10_it=0,0,0\n",
    "    nd3_it,nd5_it,nd10_it=0,0,0\n",
    "    \n",
    "    m2_du,m3_du,m5_du=0,0,0\n",
    "    nd2_du,nd3_du,nd5_du=0,0,0\n",
    "    \n",
    "    m2_int,m3_int,m5_int=0,0,0\n",
    "    nd2_int,nd3_int,nd5_int=0,0,0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for batch, data in enumerate(train_loader):\n",
    "        #將input的tuple分成三個部分\n",
    "        \n",
    "        input = { 'item': data[0],\n",
    "                  'target_item': data[1],\n",
    "                  'duration': data[2],\n",
    "                  'target_duration': data[3],\n",
    "                  'interval': data[4],\n",
    "                  'target_interval': data[5],\n",
    "                 }\n",
    "        logits_it,logits_du,logits_int = model(input)\n",
    "        l_it = logits_it\n",
    "        l_du = logits_du\n",
    "        l_int = logits_int\n",
    "        tgt_it = input['target_item']\n",
    "        tgt_du = input['target_duration']\n",
    "        tgt_int = input['target_interval']\n",
    "        \n",
    "       \n",
    "        # CROSS比較train跟target\n",
    "        loss_it = loss_fn(l_it, tgt_it)\n",
    "        loss_du = loss_fn(l_du, tgt_du)\n",
    "        loss_int = loss_fn(l_int, tgt_int)\n",
    "        \n",
    "        loss = 0.4*loss_it + 0.3*loss_du +0.3*loss_int\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_sum += loss.item()\n",
    "       \n",
    "        \n",
    "        \n",
    " \n",
    "    train_loss = train_loss_sum / len(train_loader)\n",
    "    train_time = round(timer() - start_time)\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    import heapq\n",
    "    \n",
    "   \n",
    "\n",
    "    for batch, data in tqdm(enumerate(test_loader)):   \n",
    "        input = { 'item': data[0],\n",
    "                  'target_item': data[1],\n",
    "                  'duration': data[2],\n",
    "                  'target_duration': data[3],\n",
    "                  'interval': data[4],\n",
    "                  'target_interval': data[5],\n",
    "                 }\n",
    "\n",
    "        logits_it,logits_du,logits_int = model(input)\n",
    "   \n",
    "        l_it = logits_it\n",
    "        l_du = logits_du\n",
    "        l_int = logits_int\n",
    "        tgt_it = input['target_item']\n",
    "        tgt_du = input['target_duration']\n",
    "        tgt_int = input['target_interval']\n",
    "        \n",
    "   \n",
    "        \n",
    "        l_it =  l_it.cpu().data.numpy()\n",
    "        l_du =  l_du.cpu().data.numpy()\n",
    "        l_int =  l_int.cpu().data.numpy()\n",
    "        ranks_it = 0\n",
    "        ranks3_it = 0\n",
    "        ranks5_it = 0\n",
    "        ranks10_it = 0\n",
    "        ndcg3_it=0\n",
    "        ndcg5_it=0\n",
    "        ndcg10_it=0\n",
    "        \n",
    "        ranks_du = 0\n",
    "        ranks2_du = 0\n",
    "        ranks3_du = 0\n",
    "        ranks5_du = 0\n",
    "        ndcg2_du=0\n",
    "        ndcg3_du=0\n",
    "        ndcg5_du=0\n",
    "        \n",
    "        ranks_int = 0\n",
    "        ranks2_int = 0\n",
    "        ranks3_int = 0\n",
    "        ranks5_int = 0\n",
    "        ndcg2_int=0\n",
    "        ndcg3_int=0\n",
    "        ndcg5_int=0\n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "       #####item\n",
    "        # 將前k個結果取出做比較\n",
    "        for n in range(len(l_it)):\n",
    "             \n",
    "            r3= heapq.nlargest(3, range(len(l_it[n])), l_it[n].take) \n",
    "\n",
    "            \n",
    "            for i in range(len(r3)):\n",
    "                re3_it += ((r3[i]) == tgt_it[n]).float().sum()\n",
    "                \n",
    "            r5= heapq.nlargest(5, range(len(l_it[n])), l_it[n].take)\n",
    "       \n",
    "            for i in range(len(r5)):\n",
    "                re5_it += ((r5[i]) == tgt_it[n]).float().sum()\n",
    "                \n",
    "                \n",
    "            r10= heapq.nlargest(10, range(len(l_it[n])), l_it[n].take)\n",
    "          \n",
    "            for i in range(len(r10)):\n",
    "                re10_it += ((r10[i]) ==tgt_it[n]).float().sum()\n",
    "            \n",
    "          #MRR3\n",
    "            mr3 = r3\n",
    "            for i in range(len(mr3)):\n",
    "                if (mr3[i]) == tgt_it[n]:\n",
    "                    rank3 = i + 1\n",
    "                    rranks3 = 1/rank3\n",
    "\n",
    "                    m3_it += rranks3\n",
    "                    nndcg3=(1/(np.log2(rank3+1)))\n",
    "                    nd3_it+=nndcg3\n",
    "        #MRR\n",
    "            mr5 = r5\n",
    "\n",
    "            for i in range(len(mr5)):\n",
    "               \n",
    "                if (mr5[i]) == tgt_it[n]:\n",
    "                    rank5 = i + 1\n",
    "                    rranks5 = 1/rank5\n",
    "                    m5_it += rranks5\n",
    "                    nndcg5=(1/(np.log2(rank5+1)))\n",
    "                    nd5_it+=nndcg5\n",
    "    \n",
    "    \n",
    "    #MRR\n",
    "            mr10 = r10\n",
    "\n",
    "            for i in range(len(mr10)):\n",
    "                if (mr10[i]) == tgt_it[n]:\n",
    "                    rank10 = i + 1\n",
    "                   \n",
    "                    rranks10 = 1/rank10\n",
    "                    m10_it += rranks10\n",
    "                    nndcg10=1/(np.log2(rank10+1))\n",
    "                    nd10_it+=nndcg10\n",
    "        \n",
    "         #####duration\n",
    "        # 將前k個結果取出做比較      \n",
    "        \n",
    "        \n",
    "        for n in range(len(l_du)):\n",
    "            \n",
    "            r1= heapq.nlargest(1,  range(len(l_du[n])), l_du[n].take) \n",
    "            \n",
    "            \n",
    "            for i in range(len(r1)):\n",
    "                correct_duration += (((r1[i]) == tgt_du[n]).float().sum())\n",
    "            \n",
    "            \n",
    "            r2= heapq.nlargest(2,  range(len(l_du[n])), l_du[n].take) \n",
    "                \n",
    "      \n",
    "            for i in range(len(r2)):\n",
    "                re2_du += (((r2[i]) == tgt_du[n]).float().sum())\n",
    "            \n",
    "            \n",
    "            r3= heapq.nlargest(3,  range(len(l_du[n])), l_du[n].take) \n",
    "         \n",
    "            for i in range(len(r3)):\n",
    "                re3_du += (((r3[i]) == tgt_du[n]).float().sum())\n",
    "            \n",
    "            r5= heapq.nlargest(5,  range(len(l_du[n])), l_du[n].take) \n",
    "            \n",
    "            for i in range(len(r5)):\n",
    "                re5_du += (((r5[i]) ==tgt_du[n]).float().sum())\n",
    "                \n",
    "           \n",
    "                           \n",
    "          #MRR3\n",
    "            mr2 = r2\n",
    "            for i in range(len(mr2)):\n",
    "                if ((mr2[i]) == tgt_du[n]):\n",
    "                    rank2 = i + 1\n",
    "                    rranks2 = 1/rank2\n",
    "\n",
    "                    m2_du += rranks2\n",
    "                    nndcg2=(1/(np.log2(rank2+1)))\n",
    "                    nd2_du+=nndcg2\n",
    "        #MRR\n",
    "            mr3 = r3\n",
    "\n",
    "            for i in range(len(mr3)):\n",
    "               \n",
    "                if ((mr3[i]) == tgt_du[n]):\n",
    "                    rank3 = i + 1\n",
    "                    rranks3 = 1/rank3\n",
    "                    \n",
    "                    m3_du += rranks3\n",
    "                    nndcg3=(1/(np.log2(rank3+1)))\n",
    "                    nd3_du+=nndcg3\n",
    "    \n",
    "\n",
    "    #MRR\n",
    "            mr5 = r5\n",
    "\n",
    "            for i in range(len(mr5)):\n",
    "                if ((mr5[i]) == tgt_du[n]):\n",
    "                    rank5 = i + 1\n",
    "                   \n",
    "                    rranks5 = 1/rank5\n",
    "                    m5_du += rranks5\n",
    "                    nndcg5=1/(np.log2(rank5+1))\n",
    "                    nd5_du+=nndcg5\n",
    "       \n",
    "                    \n",
    "                      \n",
    "       \n",
    "           #####interval\n",
    "        # 將前k個結果取出做比較  \n",
    "        for n in range(len(l_int)):\n",
    "            \n",
    "            \n",
    "            r1= heapq.nlargest(1,  range(len(l_int[n])), l_int[n].take) \n",
    "           \n",
    "            for i in range(len(r1)):\n",
    "                correct_interval += (((r1[i]) == tgt_int[n]).float().sum())\n",
    "            \n",
    "            \n",
    "            r2= heapq.nlargest(2,  range(len(l_int[n])), l_int[n].take) \n",
    "            \n",
    "            \n",
    "            for i in range(len(r2)):\n",
    "                re2_int += (((r2[i])) == tgt_int[n]).float().sum()\n",
    "                \n",
    "            r3= heapq.nlargest(3,  range(len(l_int[n])), l_int[n].take) \n",
    "            \n",
    "            for i in range(len(r3)):\n",
    "                re3_int += (((r3[i])) == tgt_int[n]).float().sum()\n",
    "                \n",
    "            r5= heapq.nlargest(5,  range(len(l_int[n])), l_int[n].take) \n",
    "            \n",
    "     \n",
    "            for i in range(len(r5)):\n",
    "                re5_int += (((r5[i])) == tgt_int[n]).float().sum()\n",
    "            \n",
    "          #MRR3\n",
    "            mr2 = r2\n",
    "            for i in range(len(mr2)):\n",
    "                if (((mr2[i])) == tgt_int[n]):\n",
    "                    rank2 = i + 1\n",
    "                    rranks2 = 1/rank2\n",
    "\n",
    "                    m2_int += rranks2\n",
    "                    nndcg2=(1/(np.log2(rank2+1)))\n",
    "                    nd2_int+=nndcg2\n",
    "        #MRR\n",
    "            mr3 = r3\n",
    "\n",
    "            for i in range(len(mr3)):\n",
    "               \n",
    "                if ((mr3[i])) == tgt_int[n]:\n",
    "                    rank3 = i + 1\n",
    "                    rranks3 = 1/rank3\n",
    "                    m3_int += rranks3\n",
    "                    nndcg3=(1/(np.log2(rank3+1)))\n",
    "                    nd3_int+=nndcg3\n",
    "    \n",
    " \n",
    "    #MRR\n",
    "            mr5 = r5\n",
    "\n",
    "            for i in range(len(mr5)):\n",
    "                if ((mr5[i])) == tgt_int[n]:\n",
    "                    rank5 = i + 1\n",
    "                   \n",
    "                    rranks5 = 1/rank5\n",
    "                    m5_int += rranks5\n",
    "                    nndcg5 = 1/(np.log2(rank5+1))\n",
    "                    nd5_int+=nndcg5  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "   \n",
    "    \n",
    "    recall3_it = (re3_it*100)/(len(test_data[0]))\n",
    "    \n",
    "    recall5_it = (re5_it*100)/(len(test_data[0]))\n",
    "    recall10_it = (re10_it*100)/(len(test_data[0]))\n",
    "    mrr3_it = (m3_it*100)/(len(test_data[0]))\n",
    "    mrr5_it = (m5_it*100)/(len(test_data[0]))\n",
    "    mrr10_it = (m10_it*100)/(len(test_data[0]))\n",
    "    n3_it=(nd3_it*100)/(len(test_data[0]))\n",
    "    n5_it=(nd5_it*100)/(len(test_data[0]))\n",
    "    n10_it=(nd10_it*100)/(len(test_data[0]))\n",
    "   \n",
    "        \n",
    "        \n",
    "    recall2_du = (re2_du*100)/(len(test_data[0]))\n",
    "    recall3_du = (re3_du*100)/(len(test_data[0]))\n",
    "    recall5_du = (re5_du*100)/(len(test_data[0]))\n",
    "    mrr2_du = (m2_du*100)/(len(test_data[0]))\n",
    "    mrr3_du = (m3_du*100)/(len(test_data[0]))\n",
    "    mrr5_du = (m5_du*100)/(len(test_data[0]))\n",
    "    n2_du=(nd2_du*100)/(len(test_data[0]))\n",
    "    n3_du=(nd3_du*100)/(len(test_data[0]))\n",
    "    n5_du=(nd5_du*100)/(len(test_data[0]))\n",
    "    \n",
    "        \n",
    "        \n",
    "    recall2_int = (re2_int*100)/(len(test_data[0]))\n",
    "    recall3_int = (re3_int*100)/(len(test_data[0]))\n",
    "    recall5_int = (re5_int*100)/(len(test_data[0]))\n",
    "    mrr2_int = (m2_int*100)/(len(test_data[0]))\n",
    "    mrr3_int = (m3_int*100)/(len(test_data[0]))\n",
    "    mrr5_int = (m5_int*100)/(len(test_data[0]))\n",
    "    n2_int=(nd2_int*100)/(len(test_data[0]))\n",
    "    n3_int=(nd3_int*100)/(len(test_data[0]))\n",
    "    n5_int=(nd5_int*100)/(len(test_data[0]))\n",
    "\n",
    "        \n",
    "    accuracy_du = 100 * correct_duration/(len(test_data[0]))\n",
    "    accuracy_int = 100 * correct_interval/(len(test_data[0]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    log = f\"Accuracy_Duration: {accuracy_du:.5f} Accuracy_Interval: {accuracy_int:.5f} HR3_Item: {recall3_it:.5f} HR5_Item: {recall5_it:.5f} HR10_Item: {recall10_it:.5f} HR2_du: {recall2_du:.5f} HR3_du: {recall3_du:.5f} HR5_du: {recall5_du:.5f} HR2_int: {recall2_int:.5f} HR3_int: {recall3_int:.5f} HR5_int: {recall5_int:.5f}  MRR3_item: {mrr3_it:.10f}  MRR5_item: {mrr5_it:.10f}  MRR10_item: {mrr10_it:.10f} MRR2_du: {mrr2_du:.10f}  MRR3_du: {mrr3_du:.10f}  MRR5_du: {mrr5_du:.10f} MRR2_int: {mrr2_int:.10f}  MRR3_int: {mrr3_int:.10f}  MRR5_int: {mrr5_int:.10f}  NDCG3_it: {n3_it:.10f}  NDCG5_it: {n5_it:.10f}  NDCG10_it: {n10_it:.10f}  NDCG2_du: {n2_du:.10f}  NDCG3_du: {n3_du:.10f}  NDCG5_du: {n5_du:.10f}  NDCG2_int: {n2_int:.10f}  NDCG3_int: {n3_int:.10f}  NDCG5_int: {n5_int:.10f} \"\n",
    "    print(\"train_loss_sum:\",train_loss_sum)\n",
    "    print(log)\n",
    "    \n",
    "   # print(m/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32510324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
